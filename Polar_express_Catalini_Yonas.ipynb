{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbDVUg77mjJA"
      },
      "source": [
        "**Progetto di Introduzione all'Apprendimento Automatico di Catalini Yonas \n",
        "Ernesto, mat. 0000987636**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwq1SuZHnBhX"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ynz-4_4cFmbJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import keras\n",
        "from keras import activations\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZckZ9io76W3"
      },
      "source": [
        "**Definizione generatore e funzione di accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DsA1GqAeWAdo"
      },
      "outputs": [],
      "source": [
        "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
        "    xc = (x*grid[0]).astype(int)\n",
        "    yc = (y*grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    #compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
        "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R_bQQVhvCrYN"
      },
      "outputs": [],
      "source": [
        "def my_accuracy(true_maps: tf.Tensor, my_maps: tf.Tensor) -> float:\n",
        "  return tf.reduce_mean(tf.cast(tf.equal(tf.argmax(true_maps, axis=1), tf.argmax(my_maps, axis=1)), tf.float64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      },
      "source": [
        "**Generazione training e validation (test) set**\n",
        "\n",
        "I dati generati vengono divisi tra training e validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ov3rXaLVHDCT"
      },
      "outputs": [],
      "source": [
        "bsize = 2000\n",
        "n_train = 4000000\n",
        "n_test = 40000\n",
        "g1,g2 = 10,10\n",
        "gen = polar_generator(n_train+n_test,grid=(g1,g2),noise=0.002,flat=True)\n",
        "(theta,rho),maps = next(gen)\n",
        "inputs=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(inputs,maps, test_size=n_test/(n_train+n_test),shuffle=True,random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4hntQtSWjPk"
      },
      "source": [
        "**Definizione del modello**\n",
        "\n",
        "Il modello ha un un primo layer per ogni input, in modo tale da dare il giusto peso ad entrambi i valori e non soltanto alla loro combinazione. Questi due layer vengono uniti poi uniti e passiamo attraverso due layer densi prima dell'output.\n",
        "Le dimensioni dei layer e le funzioni di attivazione sono state scelte attraverso vari test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM7R8ZZZHN7p",
        "outputId": "c47027aa-c8ed-4a1d-bf01-40bf931af42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            4           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            4           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4)            0           ['dense[0][0]',                  \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 20)           100         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            84          ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 100)          500         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 692\n",
            "Trainable params: 692\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "in1=Input(shape=(1))\n",
        "in2=Input(shape=(1))\n",
        "\n",
        "d1=Dense(2,activation=keras.activations.softsign)(in1)\n",
        "d2=Dense(2,activation=keras.activations.softsign)(in2)\n",
        "joint=tf.keras.layers.concatenate([d1,d2],axis=1)\n",
        "elab_layer=Dense(20,activation=keras.activations.relu)(joint)\n",
        "cond_layer=Dense(4,activation=keras.activations.relu)(elab_layer)\n",
        "out=Dense(100,activation=keras.activations.softmax)(cond_layer)\n",
        "\n",
        "net= Model([in1,in2],out)\n",
        "net.summary()\n",
        "\n",
        "net.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy',my_accuracy]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3w7AxFyiKhpu"
      },
      "outputs": [],
      "source": [
        "#nn = keras.models.load_model(\"mr-roboto\", custom_objects={\"my_accuracy\":my_accuracy})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp2ZY1EyUVdK"
      },
      "source": [
        "**Training**\n",
        "\n",
        "60 Epoche per questi dati sono state abbastanza, ma per sicurezza controlliamo la loss sul validation set generato inizialmente per fare early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di7VngMuKk_N",
        "outputId": "5ea5a93c-b018-42c1-b382-43b0d50ab5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 2.5411 - accuracy: 0.3560 - my_accuracy: 0.3560 - val_loss: 1.1949 - val_accuracy: 0.6759 - val_my_accuracy: 0.6759\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.8068 - accuracy: 0.7730 - my_accuracy: 0.7730 - val_loss: 0.5902 - val_accuracy: 0.8199 - val_my_accuracy: 0.8199\n",
            "Epoch 3/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.5048 - accuracy: 0.8476 - my_accuracy: 0.8476 - val_loss: 0.4428 - val_accuracy: 0.8663 - val_my_accuracy: 0.8663\n",
            "Epoch 4/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.4034 - accuracy: 0.8796 - my_accuracy: 0.8796 - val_loss: 0.3708 - val_accuracy: 0.8869 - val_my_accuracy: 0.8869\n",
            "Epoch 5/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.3425 - accuracy: 0.8993 - my_accuracy: 0.8993 - val_loss: 0.3159 - val_accuracy: 0.9073 - val_my_accuracy: 0.9073\n",
            "Epoch 6/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.2999 - accuracy: 0.9125 - my_accuracy: 0.9125 - val_loss: 0.2827 - val_accuracy: 0.9144 - val_my_accuracy: 0.9144\n",
            "Epoch 7/100\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.2701 - accuracy: 0.9217 - my_accuracy: 0.9217 - val_loss: 0.2566 - val_accuracy: 0.9249 - val_my_accuracy: 0.9249\n",
            "Epoch 8/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.2469 - accuracy: 0.9290 - my_accuracy: 0.9290 - val_loss: 0.2375 - val_accuracy: 0.9296 - val_my_accuracy: 0.9296\n",
            "Epoch 9/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.2283 - accuracy: 0.9352 - my_accuracy: 0.9352 - val_loss: 0.2202 - val_accuracy: 0.9345 - val_my_accuracy: 0.9345\n",
            "Epoch 10/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.2130 - accuracy: 0.9398 - my_accuracy: 0.9398 - val_loss: 0.2078 - val_accuracy: 0.9395 - val_my_accuracy: 0.9395\n",
            "Epoch 11/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.2007 - accuracy: 0.9433 - my_accuracy: 0.9433 - val_loss: 0.1948 - val_accuracy: 0.9457 - val_my_accuracy: 0.9457\n",
            "Epoch 12/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1901 - accuracy: 0.9464 - my_accuracy: 0.9464 - val_loss: 0.1859 - val_accuracy: 0.9451 - val_my_accuracy: 0.9451\n",
            "Epoch 13/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1812 - accuracy: 0.9487 - my_accuracy: 0.9487 - val_loss: 0.1778 - val_accuracy: 0.9474 - val_my_accuracy: 0.9474\n",
            "Epoch 14/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1735 - accuracy: 0.9508 - my_accuracy: 0.9508 - val_loss: 0.1744 - val_accuracy: 0.9459 - val_my_accuracy: 0.9459\n",
            "Epoch 15/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1668 - accuracy: 0.9524 - my_accuracy: 0.9524 - val_loss: 0.1630 - val_accuracy: 0.9541 - val_my_accuracy: 0.9541\n",
            "Epoch 16/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1609 - accuracy: 0.9542 - my_accuracy: 0.9542 - val_loss: 0.1572 - val_accuracy: 0.9553 - val_my_accuracy: 0.9553\n",
            "Epoch 17/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1557 - accuracy: 0.9557 - my_accuracy: 0.9557 - val_loss: 0.1528 - val_accuracy: 0.9562 - val_my_accuracy: 0.9562\n",
            "Epoch 18/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1511 - accuracy: 0.9567 - my_accuracy: 0.9567 - val_loss: 0.1535 - val_accuracy: 0.9519 - val_my_accuracy: 0.9519\n",
            "Epoch 19/100\n",
            "2000/2000 [==============================] - 23s 11ms/step - loss: 0.1470 - accuracy: 0.9578 - my_accuracy: 0.9578 - val_loss: 0.1430 - val_accuracy: 0.9595 - val_my_accuracy: 0.9594\n",
            "Epoch 20/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1430 - accuracy: 0.9589 - my_accuracy: 0.9589 - val_loss: 0.1405 - val_accuracy: 0.9597 - val_my_accuracy: 0.9597\n",
            "Epoch 21/100\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1396 - accuracy: 0.9597 - my_accuracy: 0.9597 - val_loss: 0.1374 - val_accuracy: 0.9606 - val_my_accuracy: 0.9606\n",
            "Epoch 22/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1366 - accuracy: 0.9602 - my_accuracy: 0.9602 - val_loss: 0.1352 - val_accuracy: 0.9601 - val_my_accuracy: 0.9601\n",
            "Epoch 23/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1339 - accuracy: 0.9608 - my_accuracy: 0.9608 - val_loss: 0.1297 - val_accuracy: 0.9643 - val_my_accuracy: 0.9643\n",
            "Epoch 24/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1310 - accuracy: 0.9616 - my_accuracy: 0.9616 - val_loss: 0.1297 - val_accuracy: 0.9623 - val_my_accuracy: 0.9623\n",
            "Epoch 25/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1288 - accuracy: 0.9620 - my_accuracy: 0.9620 - val_loss: 0.1252 - val_accuracy: 0.9636 - val_my_accuracy: 0.9636\n",
            "Epoch 26/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1265 - accuracy: 0.9624 - my_accuracy: 0.9624 - val_loss: 0.1244 - val_accuracy: 0.9635 - val_my_accuracy: 0.9635\n",
            "Epoch 27/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1243 - accuracy: 0.9630 - my_accuracy: 0.9630 - val_loss: 0.1222 - val_accuracy: 0.9645 - val_my_accuracy: 0.9645\n",
            "Epoch 28/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1222 - accuracy: 0.9636 - my_accuracy: 0.9636 - val_loss: 0.1209 - val_accuracy: 0.9649 - val_my_accuracy: 0.9649\n",
            "Epoch 29/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1205 - accuracy: 0.9638 - my_accuracy: 0.9638 - val_loss: 0.1185 - val_accuracy: 0.9652 - val_my_accuracy: 0.9652\n",
            "Epoch 30/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1187 - accuracy: 0.9643 - my_accuracy: 0.9643 - val_loss: 0.1161 - val_accuracy: 0.9665 - val_my_accuracy: 0.9665\n",
            "Epoch 31/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1171 - accuracy: 0.9646 - my_accuracy: 0.9646 - val_loss: 0.1135 - val_accuracy: 0.9680 - val_my_accuracy: 0.9680\n",
            "Epoch 32/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1152 - accuracy: 0.9653 - my_accuracy: 0.9653 - val_loss: 0.1128 - val_accuracy: 0.9685 - val_my_accuracy: 0.9684\n",
            "Epoch 33/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1142 - accuracy: 0.9652 - my_accuracy: 0.9652 - val_loss: 0.1107 - val_accuracy: 0.9685 - val_my_accuracy: 0.9685\n",
            "Epoch 34/100\n",
            "2000/2000 [==============================] - 23s 11ms/step - loss: 0.1125 - accuracy: 0.9658 - my_accuracy: 0.9658 - val_loss: 0.1140 - val_accuracy: 0.9654 - val_my_accuracy: 0.9654\n",
            "Epoch 35/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1113 - accuracy: 0.9659 - my_accuracy: 0.9659 - val_loss: 0.1155 - val_accuracy: 0.9614 - val_my_accuracy: 0.9614\n",
            "Epoch 36/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1099 - accuracy: 0.9663 - my_accuracy: 0.9663 - val_loss: 0.1082 - val_accuracy: 0.9676 - val_my_accuracy: 0.9677\n",
            "Epoch 37/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1086 - accuracy: 0.9666 - my_accuracy: 0.9666 - val_loss: 0.1066 - val_accuracy: 0.9688 - val_my_accuracy: 0.9688\n",
            "Epoch 38/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1073 - accuracy: 0.9668 - my_accuracy: 0.9668 - val_loss: 0.1075 - val_accuracy: 0.9665 - val_my_accuracy: 0.9666\n",
            "Epoch 39/100\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1062 - accuracy: 0.9671 - my_accuracy: 0.9671 - val_loss: 0.1044 - val_accuracy: 0.9686 - val_my_accuracy: 0.9686\n",
            "Epoch 40/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1051 - accuracy: 0.9674 - my_accuracy: 0.9674 - val_loss: 0.1056 - val_accuracy: 0.9662 - val_my_accuracy: 0.9662\n",
            "Epoch 41/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1043 - accuracy: 0.9675 - my_accuracy: 0.9675 - val_loss: 0.1035 - val_accuracy: 0.9679 - val_my_accuracy: 0.9679\n",
            "Epoch 42/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1031 - accuracy: 0.9679 - my_accuracy: 0.9679 - val_loss: 0.1033 - val_accuracy: 0.9673 - val_my_accuracy: 0.9673\n",
            "Epoch 43/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1022 - accuracy: 0.9680 - my_accuracy: 0.9680 - val_loss: 0.1021 - val_accuracy: 0.9673 - val_my_accuracy: 0.9673\n",
            "Epoch 44/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1012 - accuracy: 0.9683 - my_accuracy: 0.9683 - val_loss: 0.1047 - val_accuracy: 0.9657 - val_my_accuracy: 0.9657\n",
            "Epoch 45/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1005 - accuracy: 0.9684 - my_accuracy: 0.9684 - val_loss: 0.0983 - val_accuracy: 0.9694 - val_my_accuracy: 0.9694\n",
            "Epoch 46/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0995 - accuracy: 0.9686 - my_accuracy: 0.9686 - val_loss: 0.0980 - val_accuracy: 0.9692 - val_my_accuracy: 0.9692\n",
            "Epoch 47/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0989 - accuracy: 0.9687 - my_accuracy: 0.9687 - val_loss: 0.0979 - val_accuracy: 0.9692 - val_my_accuracy: 0.9692\n",
            "Epoch 48/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0978 - accuracy: 0.9690 - my_accuracy: 0.9690 - val_loss: 0.0988 - val_accuracy: 0.9685 - val_my_accuracy: 0.9685\n",
            "Epoch 49/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0971 - accuracy: 0.9692 - my_accuracy: 0.9692 - val_loss: 0.0952 - val_accuracy: 0.9704 - val_my_accuracy: 0.9705\n",
            "Epoch 50/100\n",
            "2000/2000 [==============================] - 23s 11ms/step - loss: 0.0965 - accuracy: 0.9692 - my_accuracy: 0.9692 - val_loss: 0.0952 - val_accuracy: 0.9698 - val_my_accuracy: 0.9698\n",
            "Epoch 51/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0957 - accuracy: 0.9695 - my_accuracy: 0.9695 - val_loss: 0.0970 - val_accuracy: 0.9685 - val_my_accuracy: 0.9684\n",
            "Epoch 52/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0950 - accuracy: 0.9698 - my_accuracy: 0.9698 - val_loss: 0.0967 - val_accuracy: 0.9677 - val_my_accuracy: 0.9677\n",
            "Epoch 53/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0941 - accuracy: 0.9701 - my_accuracy: 0.9701 - val_loss: 0.0941 - val_accuracy: 0.9706 - val_my_accuracy: 0.9706\n",
            "Epoch 54/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0935 - accuracy: 0.9702 - my_accuracy: 0.9702 - val_loss: 0.0923 - val_accuracy: 0.9704 - val_my_accuracy: 0.9704\n",
            "Epoch 55/100\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.0931 - accuracy: 0.9701 - my_accuracy: 0.9701 - val_loss: 0.0913 - val_accuracy: 0.9720 - val_my_accuracy: 0.9720\n",
            "Epoch 56/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0922 - accuracy: 0.9705 - my_accuracy: 0.9705 - val_loss: 0.0951 - val_accuracy: 0.9683 - val_my_accuracy: 0.9684\n",
            "Epoch 57/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0914 - accuracy: 0.9706 - my_accuracy: 0.9706 - val_loss: 0.0880 - val_accuracy: 0.9734 - val_my_accuracy: 0.9734\n",
            "Epoch 58/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0906 - accuracy: 0.9709 - my_accuracy: 0.9709 - val_loss: 0.0891 - val_accuracy: 0.9726 - val_my_accuracy: 0.9727\n",
            "Epoch 59/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0900 - accuracy: 0.9710 - my_accuracy: 0.9710 - val_loss: 0.0901 - val_accuracy: 0.9711 - val_my_accuracy: 0.9712\n",
            "Epoch 60/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.0893 - accuracy: 0.9712 - my_accuracy: 0.9712 - val_loss: 0.0896 - val_accuracy: 0.9700 - val_my_accuracy: 0.9700\n",
            "Epoch 61/100\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.0890 - accuracy: 0.9711 - my_accuracy: 0.9711 - val_loss: 0.0906 - val_accuracy: 0.9707 - val_my_accuracy: 0.9708\n",
            "Epoch 62/100\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.0885 - accuracy: 0.9711 - my_accuracy: 0.9711 - val_loss: 0.0880 - val_accuracy: 0.9709 - val_my_accuracy: 0.9709\n"
          ]
        }
      ],
      "source": [
        "history = net.fit(\n",
        "  x=[x_train[:,0],x_train[:,1]],\n",
        "  y=y_train,\n",
        "  epochs=100,\n",
        "  batch_size=bsize,\n",
        "  validation_data=([x_test[:,0],x_test[:,1]], y_test),\n",
        "  callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x0pVsmKURoi"
      },
      "source": [
        "**Testing**\n",
        "\n",
        "Testo la rete 100 volte e stampo quanti di questi test risultano in accuracy inferiore al 95% e l'accuracy media.\n",
        "Con questo modello l'accuracy media Ã¨ sempre circa 96%, e i test che vanno sotto il 95% sono di solito intorno a 15/100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYRZpeRuSrTv",
        "outputId": "d6cd2bec-a4ef-4d3d-ae69-463a93e0ace3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2127 - accuracy: 0.9145 - my_accuracy: 0.9145\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9602 - my_accuracy: 0.9602\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0895 - accuracy: 0.9698 - my_accuracy: 0.9698\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0934 - accuracy: 0.9673 - my_accuracy: 0.9673\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 0.9590 - my_accuracy: 0.9590\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9513 - my_accuracy: 0.9513\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 0.9468 - my_accuracy: 0.9468\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.9409 - my_accuracy: 0.9410\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1017 - accuracy: 0.9622 - my_accuracy: 0.9622\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9522 - my_accuracy: 0.9522\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.9468 - my_accuracy: 0.9468\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0984 - accuracy: 0.9648 - my_accuracy: 0.9648\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9458 - my_accuracy: 0.9458\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0984 - accuracy: 0.9649 - my_accuracy: 0.9649\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0984 - accuracy: 0.9628 - my_accuracy: 0.9628\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.9716 - my_accuracy: 0.9716\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0889 - accuracy: 0.9711 - my_accuracy: 0.9710\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1026 - accuracy: 0.9616 - my_accuracy: 0.9616\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1145 - accuracy: 0.9564 - my_accuracy: 0.9564\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9491 - my_accuracy: 0.9491\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0911 - accuracy: 0.9673 - my_accuracy: 0.9673\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0978 - accuracy: 0.9649 - my_accuracy: 0.9649\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1106 - accuracy: 0.9579 - my_accuracy: 0.9579\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9538 - my_accuracy: 0.9538\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1193 - accuracy: 0.9517 - my_accuracy: 0.9517\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0906 - accuracy: 0.9692 - my_accuracy: 0.9692\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1915 - accuracy: 0.9218 - my_accuracy: 0.9217\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0936 - accuracy: 0.9685 - my_accuracy: 0.9685\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0893 - accuracy: 0.9701 - my_accuracy: 0.9701\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1183 - accuracy: 0.9532 - my_accuracy: 0.9532\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1360 - accuracy: 0.9440 - my_accuracy: 0.9440\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1014 - accuracy: 0.9609 - my_accuracy: 0.9609\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1301 - accuracy: 0.9463 - my_accuracy: 0.9463\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0948 - accuracy: 0.9661 - my_accuracy: 0.9661\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0890 - accuracy: 0.9707 - my_accuracy: 0.9707\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1029 - accuracy: 0.9604 - my_accuracy: 0.9604\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1118 - accuracy: 0.9575 - my_accuracy: 0.9575\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1149 - accuracy: 0.9552 - my_accuracy: 0.9552\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9534 - my_accuracy: 0.9534\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1049 - accuracy: 0.9614 - my_accuracy: 0.9614\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.9578 - my_accuracy: 0.9578\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1086 - accuracy: 0.9575 - my_accuracy: 0.9575\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0983 - accuracy: 0.9647 - my_accuracy: 0.9647\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9637 - my_accuracy: 0.9637\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.9651 - my_accuracy: 0.9651\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.9681 - my_accuracy: 0.9681\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0896 - accuracy: 0.9693 - my_accuracy: 0.9693\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0954 - accuracy: 0.9661 - my_accuracy: 0.9660\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0941 - accuracy: 0.9672 - my_accuracy: 0.9672\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0934 - accuracy: 0.9675 - my_accuracy: 0.9675\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0944 - accuracy: 0.9668 - my_accuracy: 0.9668\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1121 - accuracy: 0.9549 - my_accuracy: 0.9549\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0900 - accuracy: 0.9699 - my_accuracy: 0.9699\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.9604 - my_accuracy: 0.9604\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1171 - accuracy: 0.9540 - my_accuracy: 0.9540\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.9675 - my_accuracy: 0.9674\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0894 - accuracy: 0.9695 - my_accuracy: 0.9695\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0967 - accuracy: 0.9655 - my_accuracy: 0.9655\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0905 - accuracy: 0.9686 - my_accuracy: 0.9686\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1008 - accuracy: 0.9623 - my_accuracy: 0.9623\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1308 - accuracy: 0.9455 - my_accuracy: 0.9455\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1042 - accuracy: 0.9599 - my_accuracy: 0.9599\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0895 - accuracy: 0.9697 - my_accuracy: 0.9697\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1011 - accuracy: 0.9616 - my_accuracy: 0.9616\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.9424 - my_accuracy: 0.9424\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0986 - accuracy: 0.9627 - my_accuracy: 0.9627\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1767 - accuracy: 0.9334 - my_accuracy: 0.9334\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1020 - accuracy: 0.9625 - my_accuracy: 0.9625\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0998 - accuracy: 0.9633 - my_accuracy: 0.9633\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1145 - accuracy: 0.9543 - my_accuracy: 0.9543\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0939 - accuracy: 0.9682 - my_accuracy: 0.9682\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1735 - accuracy: 0.9359 - my_accuracy: 0.9359\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0988 - accuracy: 0.9629 - my_accuracy: 0.9629\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0968 - accuracy: 0.9646 - my_accuracy: 0.9646\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0997 - accuracy: 0.9637 - my_accuracy: 0.9637\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0979 - accuracy: 0.9637 - my_accuracy: 0.9637\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1095 - accuracy: 0.9574 - my_accuracy: 0.9574\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1695 - accuracy: 0.9363 - my_accuracy: 0.9363\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1031 - accuracy: 0.9598 - my_accuracy: 0.9598\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0998 - accuracy: 0.9631 - my_accuracy: 0.9631\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1001 - accuracy: 0.9626 - my_accuracy: 0.9626\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1011 - accuracy: 0.9629 - my_accuracy: 0.9629\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0977 - accuracy: 0.9645 - my_accuracy: 0.9645\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0948 - accuracy: 0.9678 - my_accuracy: 0.9678\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1323 - accuracy: 0.9485 - my_accuracy: 0.9485\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.9507 - my_accuracy: 0.9507\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1018 - accuracy: 0.9611 - my_accuracy: 0.9611\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9719 - my_accuracy: 0.9719\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1498 - accuracy: 0.9394 - my_accuracy: 0.9394\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9599 - my_accuracy: 0.9599\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.9599 - my_accuracy: 0.9599\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0907 - accuracy: 0.9682 - my_accuracy: 0.9681\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1247 - accuracy: 0.9476 - my_accuracy: 0.9476\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0934 - accuracy: 0.9674 - my_accuracy: 0.9674\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0961 - accuracy: 0.9646 - my_accuracy: 0.9646\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 0.9454 - my_accuracy: 0.9454\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1083 - accuracy: 0.9574 - my_accuracy: 0.9574\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0957 - accuracy: 0.9649 - my_accuracy: 0.9649\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0942 - accuracy: 0.9661 - my_accuracy: 0.9661\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0881 - accuracy: 0.9715 - my_accuracy: 0.9715\n",
            "Mean Accuracy: 95.9%\n",
            "N. of tests with less accuracy than 95%: 18/100\n"
          ]
        }
      ],
      "source": [
        "gen = polar_generator(n_test,grid=(g1,g2),noise=0.002,flat=True)\n",
        "accs = 0.0\n",
        "lower = 0\n",
        "tests = 100\n",
        "for i in range(tests):\n",
        "  (theta,rho),y = next(gen)\n",
        "  x=np.array([i for i in zip(theta,rho)])\n",
        "  score, _, acc = net.evaluate((x[:,0],x[:,1]), y, batch_size=bsize)\n",
        "  accs += acc\n",
        "  if acc < 0.95:\n",
        "    lower += 1\n",
        "\n",
        "print('Mean Accuracy: {:.1f}%'.format(accs/tests*100))\n",
        "print('N. of tests with less accuracy than 95%: {}/{}'.format(lower, tests))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E9UpJAUWxc8H"
      },
      "outputs": [],
      "source": [
        "#net.save('mr-roboto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "51liMRn3Kz_9"
      },
      "outputs": [],
      "source": [
        "#!zip -r mr-roboto.zip mr-roboto"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}